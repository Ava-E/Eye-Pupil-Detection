{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6aa62e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14d53ec",
   "metadata": {},
   "source": [
    "# Detecting eyes in webcam video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc13ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press q to quit program.\n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    eyes = eye_cascade.detectMultiScale(gray, 1.3,5)\n",
    "    for (ex, ey, ew, eh) in eyes :\n",
    "        cv2.rectangle(frame, (ex, ey), (ex + ew, ey + eh), (255, 0, 0), 5)\n",
    "        \n",
    "    if success ==True:\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(1)== ord('q'):\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e602cc",
   "metadata": {},
   "source": [
    "# Detecting eyes in video clip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fded746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press q to quit program.\n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:/Ava/Datasets/Images/video2.mp4\")\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    eyes = eye_cascade.detectMultiScale(gray, 1.3,5)\n",
    "    for (ex, ey, ew, eh) in eyes :\n",
    "        cv2.rectangle(frame, (ex, ey), (ex + ew, ey + eh), (255, 0, 0), 5)\n",
    "        \n",
    "    if success ==True:\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(1)== ord('q'):\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71dc69c",
   "metadata": {},
   "source": [
    "# Detecting pupils in video clip directly without detecting eyes first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e8bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press q to quit the program.\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:/Ava/Datasets/Images/video2.mp4\")\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if success == True:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray_blur= cv2.GaussianBlur(gray, (7,7), 0)\n",
    "        _, threshold = cv2.threshold(gray_blur, 3, 255, cv2.THRESH_BINARY_INV)\n",
    "       \n",
    "        contours, hierarchy = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if (area > 100) & (area <1000):\n",
    "                #cv2.drawContours(frame, [contour], -1 , (0,255,0),3)\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                if max(w,h)/min(w, h)<1.30:\n",
    "                    #cv2.rectangle(frame, (x, y), (x +w, y + h), (0,0,255), 3  )\n",
    "                    centre_x = int(x + w/2)\n",
    "                    centre_y = int(y + h/2)\n",
    "                    cv2.circle(frame,(centre_x, centre_y), 20, (255,0,0), 3 )\n",
    "    \n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(30)== ord('q'):\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58722e7",
   "metadata": {},
   "source": [
    "# Detecting eyes and then pupils in video clip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e378230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Press q to quit the program. \n",
    "\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:/Ava/Datasets/Images/video2.mp4\")\n",
    "cap.set(3, 640)\n",
    "cap.set(4, 480)\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    eyes = eye_cascade.detectMultiScale(gray, 1.3,7)\n",
    "    for (ex, ey, ew, eh) in eyes :\n",
    "        cv2.rectangle(frame, (ex, ey), (ex + ew, ey + eh), (255, 0, 0), 5)\n",
    "        roi = frame[ey: ey + eh, ex: ex + ew]\n",
    "        roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "        roi_blur= cv2.GaussianBlur(roi_gray, (7,7), 0)\n",
    "        _, threshold = cv2.threshold(roi_blur, 3, 255, cv2.THRESH_BINARY_INV)\n",
    "        contours, hierarchy = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > 100:\n",
    "            #if (area > 100) & (area <1000):\n",
    "                #cv2.drawContours(frame, [contour], -1 , (0,255,0),3)\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                if max(w,h)/min(w, h)<1.30:\n",
    "                    #cv2.rectangle(frame, (x, y), (x +w, y + h), (0,0,255), 3  )\n",
    "                    centre_x = int(x + w/2)\n",
    "                    centre_y = int(y + h/2)\n",
    "                    cv2.circle(roi,(centre_x, centre_y), 20, (255,0,0), 3 )\n",
    "    if success == True:\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(30 )== ord('q'):\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
